{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "613d2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source Constants\n",
    "DATA_SOURCE_ROOT = \"../../dtc-capstone-data/slack-data\" \n",
    "COURSE_CHANNEL = \"course-data-engineering\"\n",
    "WELCOME_CHANNEL = \"welcome\"\n",
    "USERS_DATA = \"users.json\"\n",
    "# book-of-the-week\n",
    "# announcements-course-data-engineering\n",
    "# shameless-content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce93364",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Target Constants\n",
    "PROJECT_ID = os.environ.get(\"GCP_PROJECT_ID\", 'dtc-capstone-344019')\n",
    "BUCKET = os.environ.get(\"GCP_GCS_BUCKET\", 'dtc_data_lake_blissful-scout-339008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d028e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7bfaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77830202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('dtc-capstone') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6dfcf",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ea6eb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_SOURCE_ROOT}/{USERS_DATA}') as f_in:\n",
    "    all_users = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Store Raw Data to datalake...\n",
    "\n",
    "def upload_to_gcs(bucket, object_name, local_file):\n",
    "    \"\"\"\n",
    "    Ref: https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python\n",
    "    :param bucket: GCS bucket name\n",
    "    :param object_name: target path & file-name\n",
    "    :param local_file: source path & file-name\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # WORKAROUND to prevent timeout for files > 6 MB on 800 kbps upload speed.\n",
    "    # (Ref: https://github.com/googleapis/python-storage/issues/74)\n",
    "    storage.blob._MAX_MULTIPART_SIZE = 5 * 1024 * 1024  # 5 MB\n",
    "    storage.blob._DEFAULT_CHUNKSIZE = 5 * 1024 * 1024  # 5 MB\n",
    "    # End of Workaround\n",
    "\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket)\n",
    "\n",
    "    blob = bucket.blob(object_name)\n",
    "    blob.upload_from_filename(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6e49182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_user_data(d):\n",
    "    identity = [\"name\", \"real_name\"]\n",
    "    location = [\"tz\",\"tz_label\", \"tz_offset\"]\n",
    "    status = [\"deleted\", \"is_admin\", \"is_owner\", \"is_primary_owner\",\n",
    "              \"is_restricted\",\"is_ultra_restricted\",\"is_bot\", \n",
    "              \"is_email_confirmed\"]\n",
    "    \n",
    "    user = {}\n",
    "    for key, value in {\"identifiers\": identity, \"location\":location, \"status\":status}.items():\n",
    "        user[key]={}\n",
    "        user[key][\"id\"] = d[\"id\"]\n",
    "        for v in value:\n",
    "            if v in d:\n",
    "                user[key][v]=d[v]\n",
    "            else:\n",
    "                user[key][v]=\"None\"   \n",
    "                \n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "76ef8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [format_user_data(d) for d in all_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cdedbe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_identity = [u[\"identifiers\"] for u in users]\n",
    "users_location = [u[\"location\"] for u in users]\n",
    "users_status = [u[\"status\"] for u in users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "156c7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_id = types.StructType([\n",
    "    types.StructField('id', types.StringType(), False),\n",
    "    types.StructField('name', types.StringType(), True),\n",
    "    types.StructField('real_name', types.StringType(), True)\n",
    "])\n",
    "\n",
    "schema_loc = types.StructType([\n",
    "    types.StructField(\"tz\", types.StringType(), True),\n",
    "    types.StructField(\"tz_label\", types.StringType(), True),\n",
    "    types.StructField(\"tz_offset\", types.StringType(), True),\n",
    "])\n",
    "\n",
    "schema_status = types.StructType([\n",
    "    types.StructField(\"deleted\", types.StringType(), True),\n",
    "    types.StructField(\"is_admin\", types.StringType(), True),\n",
    "    types.StructField(\"is_owner\", types.StringType(), True),\n",
    "    types.StructField(\"is_primary_owner\", types.StringType(), True),\n",
    "    types.StructField(\"is_restricted\", types.StringType(), True),\n",
    "    types.StructField(\"is_ultra_restricted\", types.StringType(), True),\n",
    "    types.StructField(\"is_bot\", types.StringType(), True),\n",
    "    types.StructField(\"is_email_confirmed\", types.StringType(), True),\n",
    "])\n",
    "\n",
    "# Create data frame\n",
    "df_users_identity = spark.createDataFrame(users_identity, schema_id)\n",
    "df_users_location = spark.createDataFrame(users_location, schema_loc)\n",
    "df_users_status = spark.createDataFrame(users_status, schema_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14054288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Raw data..\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition Data and read to dwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c68322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition Data\n",
    "df.repartition(24) \\\n",
    "    .write.parquet('data/pq/fhvhv/', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db8bf7cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3219257195.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [85]\u001b[0;36m\u001b[0m\n\u001b[0;31m    .option(\"inferSchema\", \"true\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "ordersDf = spark.read.format(\"json\")\n",
    "                .option(\"inferSchema\", \"true\")\n",
    "                .option(\"multiLine\", \"true\")\n",
    "                .load(users_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e67a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e6d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baac0d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_course_channel = sorted(glob(f'{DATA_SOURCE_ROOT}/{COURSE_CHANNEL}/*.json'))\n",
    "len(files_course_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa36a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294b618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01d3aa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2020-11-22', '2022-03-14')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## yyyy-mm-dd\n",
    "start, end = files_course_channel[0].split(\"/\")[-1].split(\".\")[0], files_course_channel[-1].split(\"/\")[-1].split(\".\")[0]\n",
    "(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f53fa744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(files):\n",
    "    all_docs = []\n",
    "\n",
    "    for f in files:\n",
    "        with open(f) as f_in:\n",
    "            docs = json.load(f_in)\n",
    "            all_docs.extend(docs)\n",
    "    \n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30714df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user(d):\n",
    "    p = d['profile']\n",
    "    name = p['display_name']\n",
    "    if len(name) == 0:\n",
    "        name = p['real_name']\n",
    "    return {\n",
    "        'name': name,\n",
    "        'image': p['image_72']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5f2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
